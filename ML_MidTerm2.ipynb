{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOE2Evx4maRbkzSD5DzxQ+h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abdipourasl/Machine-Learning-1402/blob/main/ML_MidTerm2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQPNR08rglpt"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "<h1>Machine Learning MidTermProject<h1>\n",
        "Amin Abdipour 401133011</h1>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/jakesnell/ove-polya-gamma-gp.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "HstIo3_6WrrU",
        "outputId": "eb0c6165-9fb3-4a41-dec4-ced16ae88ee8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-3-3e976e08aef0>, line 2)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-3e976e08aef0>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    pip install imagecorruptions\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install imagecorruptions gpytorch pypolyagamma sacred tensorboardX tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9hSjYd6JwQU",
        "outputId": "97edc7c2-fc02-465a-a76c-27ab9eb676fe"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imagecorruptions in /usr/local/lib/python3.10/dist-packages (1.1.2)\n",
            "Requirement already satisfied: gpytorch in /usr/local/lib/python3.10/dist-packages (1.11)\n",
            "Collecting pypolyagamma\n",
            "  Downloading pypolyagamma-1.2.3.tar.gz (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.6/151.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sacred\n",
            "  Downloading sacred-0.8.5-py2.py3-none-any.whl (107 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.9/107.9 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboardX\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.2)\n",
            "Requirement already satisfied: Pillow>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from imagecorruptions) (9.4.0)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.10/dist-packages (from imagecorruptions) (1.25.2)\n",
            "Requirement already satisfied: opencv-python>=3.4.5 in /usr/local/lib/python3.10/dist-packages (from imagecorruptions) (4.8.0.76)\n",
            "Requirement already satisfied: scikit-image>=0.15 in /usr/local/lib/python3.10/dist-packages (from imagecorruptions) (0.19.3)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from imagecorruptions) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from gpytorch) (1.2.2)\n",
            "Requirement already satisfied: linear-operator>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from gpytorch) (0.5.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from pypolyagamma) (3.7.1)\n",
            "Collecting docopt<1.0,>=0.3 (from sacred)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jsonpickle>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from sacred) (3.0.2)\n",
            "Collecting munch<5.0,>=2.5 (from sacred)\n",
            "  Downloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n",
            "Requirement already satisfied: wrapt<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from sacred) (1.14.1)\n",
            "Requirement already satisfied: py-cpuinfo>=4.0 in /usr/local/lib/python3.10/dist-packages (from sacred) (9.0.0)\n",
            "Collecting colorama>=0.4 (from sacred)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: packaging>=18.0 in /usr/local/lib/python3.10/dist-packages (from sacred) (23.2)\n",
            "Collecting GitPython (from sacred)\n",
            "  Downloading GitPython-3.1.42-py3-none-any.whl (195 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (3.20.3)\n",
            "Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.10/dist-packages (from linear-operator>=0.5.0->gpytorch) (2.1.0+cu121)\n",
            "Requirement already satisfied: jaxtyping>=0.2.9 in /usr/local/lib/python3.10/dist-packages (from linear-operator>=0.5.0->gpytorch) (0.2.25)\n",
            "Requirement already satisfied: typeguard~=2.13.3 in /usr/local/lib/python3.10/dist-packages (from linear-operator>=0.5.0->gpytorch) (2.13.3)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.15->imagecorruptions) (3.2.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.15->imagecorruptions) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.15->imagecorruptions) (2024.2.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.15->imagecorruptions) (1.5.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython->sacred)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pypolyagamma) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pypolyagamma) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pypolyagamma) (4.48.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pypolyagamma) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pypolyagamma) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pypolyagamma) (2.8.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->gpytorch) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->gpytorch) (3.2.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython->sacred)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.10/dist-packages (from jaxtyping>=0.2.9->linear-operator>=0.5.0->gpytorch) (4.9.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->pypolyagamma) (1.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->linear-operator>=0.5.0->gpytorch) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->linear-operator>=0.5.0->gpytorch) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->linear-operator>=0.5.0->gpytorch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->linear-operator>=0.5.0->gpytorch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->linear-operator>=0.5.0->gpytorch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11->linear-operator>=0.5.0->gpytorch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11->linear-operator>=0.5.0->gpytorch) (1.3.0)\n",
            "Building wheels for collected packages: pypolyagamma, docopt\n",
            "  Building wheel for pypolyagamma (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypolyagamma: filename=pypolyagamma-1.2.3-cp310-cp310-linux_x86_64.whl size=778509 sha256=3333bb7c430d6b218924659039e81f444a415d46fc93fd7e02564303a175eb7d\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/83/bd/0378099f2c88026b81d825c119a47b94f100f1e748b2be04fa\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=af0d2cbbc51ed8348d5e14e959b8b4dd06774ff1463a2f46a84c060145aad184\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built pypolyagamma docopt\n",
            "Installing collected packages: docopt, tensorboardX, smmap, munch, colorama, gitdb, pypolyagamma, GitPython, sacred\n",
            "Successfully installed GitPython-3.1.42 colorama-0.4.6 docopt-0.6.2 gitdb-4.0.11 munch-4.0.0 pypolyagamma-1.2.3 sacred-0.8.5 smmap-5.0.1 tensorboardX-2.6.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "yyWdAdhxUku5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "import torch.optim\n",
        "import os\n",
        "import sys\n",
        "sys.path.append('/content/ove-polya-gamma-gp/data')  # Adjust the path accordingly\n",
        "sys.path.append('/content/ove-polya-gamma-gp')  # Adjust the path accordingly\n",
        "sys.path.append('/content/ove-polya-gamma-gp/methods')  # Adjust the path accordingly\n",
        "sys.path.append('/content/ove-polya-gamma-gp/filelists')  # Adjust the path accordingly\n",
        "\n",
        "\n",
        "import configs\n",
        "import backbone\n",
        "from data.datamgr import SimpleDataManager, SetDataManager\n",
        "from methods.baselinetrain import BaselineTrain\n",
        "from methods.ove_polya_gamma_gp import OVEPolyaGammaGP, PredictiveOVEPolyaGammaGP\n",
        "from methods.logistic_softmax_gp import LogisticSoftmaxGP, PredictiveLogisticSoftmaxGP\n",
        "from methods.bayesian_maml import BayesianMAML, ChaserBayesianMAML\n",
        "from methods.gpnet import GPNet\n",
        "from methods.protonet import ProtoNet\n",
        "from methods.matchingnet import MatchingNet\n",
        "from methods.relationnet import RelationNet\n",
        "from methods.maml import MAML\n",
        "from io_utils import model_dict\n",
        "\n",
        "from methods.ove_polya_gamma_gp import kernel_ingredient\n",
        "\n",
        "from tensorboardX import SummaryWriter\n",
        "\n",
        "from sacred import Experiment\n",
        "from sacred.observers import FileStorageObserver\n",
        "\n",
        "\n",
        "EXPERIMENT_NAME = \"train\"\n",
        "RUN_DIR = \"runs\"\n",
        "\n",
        "\n",
        "def get_save_dir():\n",
        "    return os.path.join(\"runs\", EXPERIMENT_NAME)\n",
        "\n",
        "ex = Experiment(EXPERIMENT_NAME, ingredients=[kernel_ingredient], interactive=True)\n",
        "ex.observers.append(FileStorageObserver(get_save_dir()))\n",
        "\n",
        "\n",
        "@ex.config\n",
        "def get_config():\n",
        "    # Seed for Numpy and pyTorch. Default: 0 (None)\n",
        "    seed = 0\n",
        "\n",
        "    # CUB/miniImagenet/cross/omniglot/cross_char\n",
        "    dataset = \"CUB\"\n",
        "\n",
        "    # model: Conv{4|6} / ResNet{10|18|34|50|101}\n",
        "    model = \"Conv4\"\n",
        "\n",
        "    # relationnet_softmax replace L2 norm with softmax to expedite training,\n",
        "    # maml_approx use first-order approximation in the gradient for efficiency\n",
        "    # ove_polya_gamma_gp/predictive_ove_polya_gamma_gp/baseline/baseline++/protonet/matchingnet/relationnet{_softmax}/maml{_approx}\n",
        "    method = \"baseline\"\n",
        "\n",
        "    # baseline and baseline++ would ignore this parameter\n",
        "    # class num to classify for training\n",
        "    train_n_way = 5\n",
        "\n",
        "    # baseline and baseline++ only use this parameter in finetuning\n",
        "    # class num to classify for testing (validation)\n",
        "    test_n_way = 5\n",
        "\n",
        "    # baseline and baseline++ only use this parameter in finetuning\n",
        "    # number of labeled data in each class, same as n_support\n",
        "    n_shot = 5\n",
        "\n",
        "    # still required for save_features.py and test.py to find the model path correctly\n",
        "    # perform data augmentation or not during training\n",
        "    train_aug = False\n",
        "\n",
        "    # make it larger than the maximum label value in base class\n",
        "    # total number of classes in softmax, only used in baseline\n",
        "    num_classes = 200\n",
        "\n",
        "    # Save frequency\n",
        "    save_freq = 10\n",
        "\n",
        "    # Starting epoch\n",
        "    start_epoch = 0\n",
        "\n",
        "    # for meta-learning methods, each epoch contains 100 episodes.\n",
        "    # The default epoch number is dataset dependent. See train.py\n",
        "    # Stopping epoch\n",
        "    stop_epoch = -1\n",
        "\n",
        "    # optimizer to use\n",
        "    optimization = \"Adam\"\n",
        "\n",
        "    # num_draws for ove_polya_gamma_gp\n",
        "    num_draws = None\n",
        "\n",
        "    # num_steps for ove_polya_gamma_gp\n",
        "    num_steps = None\n",
        "\n",
        "    sigma = None\n",
        "\n",
        "    # tag (for logging purposes)\n",
        "    tag = \"default\"\n",
        "\n",
        "\n",
        "@ex.capture\n",
        "def get_base_file(dataset):\n",
        "    if dataset == \"cross\":\n",
        "        return configs.data_dir[\"miniImagenet\"] + \"all.json\"\n",
        "    elif dataset == \"cross_char\":\n",
        "        return configs.data_dir[\"omniglot\"] + \"noLatin.json\"\n",
        "    else:\n",
        "        return configs.data_dir[dataset] + \"base.json\"\n",
        "\n",
        "\n",
        "@ex.capture\n",
        "def get_val_file(dataset):\n",
        "    if dataset == \"cross\":\n",
        "        return configs.data_dir[\"CUB\"] + \"val.json\"\n",
        "    elif dataset == \"cross_char\":\n",
        "        return configs.data_dir[\"emnist\"] + \"val.json\"\n",
        "    else:\n",
        "        return configs.data_dir[dataset] + \"val.json\"\n",
        "\n",
        "\n",
        "@ex.capture\n",
        "def get_image_size(model, dataset):\n",
        "    if \"Conv\" in model:\n",
        "        if dataset in [\"omniglot\", \"cross_char\"]:\n",
        "            return 28\n",
        "        else:\n",
        "            return 84\n",
        "    else:\n",
        "        return 224\n",
        "\n",
        "\n",
        "@ex.capture\n",
        "def get_stop_epoch(n_shot, method, dataset, stop_epoch):\n",
        "    if stop_epoch == -1:\n",
        "        if method in [\"baseline\", \"baseline++\"]:\n",
        "            if dataset in [\"omniglot\", \"cross_char\"]:\n",
        "                stop_epoch = 5\n",
        "            elif dataset in [\"CUB\"]:\n",
        "                # This is different as stated in the open-review paper. However,\n",
        "                # using 400 epoch in baseline actually lead to over-fitting\n",
        "                stop_epoch = 200\n",
        "            elif dataset in [\"miniImagenet\", \"cross\"]:\n",
        "                stop_epoch = 400\n",
        "            else:\n",
        "                stop_epoch = 400  # default\n",
        "        else:  # meta-learning methods\n",
        "            if n_shot == 1:\n",
        "                stop_epoch = 600\n",
        "            elif n_shot == 5:\n",
        "                stop_epoch = 400\n",
        "            else:\n",
        "                stop_epoch = 600  # default\n",
        "\n",
        "    return stop_epoch\n",
        "\n",
        "\n",
        "@ex.capture\n",
        "def get_n_query(test_n_way, train_n_way):\n",
        "    # if test_n_way is smaller than train_n_way, reduce n_query to keep batch size small\n",
        "    return max(1, int(16 * test_n_way / train_n_way))\n",
        "\n",
        "\n",
        "@ex.capture\n",
        "def get_base_loader(method, train_n_way, n_shot, train_aug):\n",
        "    if method in [\"baseline\", \"baseline++\"]:\n",
        "        base_datamgr = SimpleDataManager(get_image_size(), batch_size=16)\n",
        "    else:\n",
        "        base_datamgr = SetDataManager(\n",
        "            get_image_size(), n_query=get_n_query(), n_way=train_n_way, n_support=n_shot\n",
        "        )  # n_eposide=100\n",
        "\n",
        "    return base_datamgr.get_data_loader(get_base_file(), aug=train_aug)\n",
        "\n",
        "\n",
        "@ex.capture\n",
        "def get_val_loader(method, test_n_way, n_shot, train_aug):\n",
        "    if method in [\"baseline\", \"baseline++\"]:\n",
        "        val_datamgr = SimpleDataManager(get_image_size(), batch_size=64)\n",
        "    else:\n",
        "        val_datamgr = SetDataManager(\n",
        "            get_image_size(), n_query=get_n_query(), n_way=test_n_way, n_support=n_shot\n",
        "        )\n",
        "\n",
        "    return val_datamgr.get_data_loader(get_val_file(), aug=False)\n",
        "\n",
        "\n",
        "@ex.capture\n",
        "def validate_config(dataset, model, method, num_classes, train_aug):\n",
        "    # dataset checks\n",
        "    if dataset in [\"omniglot\", \"cross_char\"]:\n",
        "        assert (\n",
        "            model == \"Conv4S\" and train_aug is False\n",
        "        ), \"omniglot only support Conv4 without augmentation\"\n",
        "\n",
        "    # method checks\n",
        "    if method in [\"baseline\", \"baseline++\"]:\n",
        "        if dataset == \"omniglot\":\n",
        "            assert (\n",
        "                num_classes >= 4112\n",
        "            ), \"class number need to be larger than max label id in base class\"\n",
        "        if dataset == \"cross_char\":\n",
        "            assert (\n",
        "                num_classes >= 1597\n",
        "            ), \"class number need to be larger than max label id in base class\"\n",
        "\n",
        "\n",
        "@ex.capture\n",
        "def get_model(\n",
        "    model,\n",
        "    dataset,\n",
        "    method,\n",
        "    num_classes,\n",
        "    train_n_way,\n",
        "    n_shot,\n",
        "    num_draws,\n",
        "    num_steps,\n",
        "    sigma,\n",
        "):\n",
        "    train_few_shot_params = dict(n_way=train_n_way, n_support=n_shot)\n",
        "\n",
        "    if method == \"baseline\":\n",
        "        return BaselineTrain(model_dict[model], num_classes)\n",
        "    elif method == \"baseline++\":\n",
        "        return BaselineTrain(model_dict[model], num_classes, loss_type=\"dist\")\n",
        "    elif method == \"ove_polya_gamma_gp\":\n",
        "        model = OVEPolyaGammaGP(model_dict[model], **train_few_shot_params)\n",
        "        if num_draws is not None:\n",
        "            model.num_draws = num_draws\n",
        "        if num_steps is not None:\n",
        "            model.num_steps = num_steps\n",
        "        if sigma is not None:\n",
        "            model.kernel.sigma = sigma\n",
        "        return model\n",
        "    elif method == \"predictive_ove_polya_gamma_gp\":\n",
        "        model = PredictiveOVEPolyaGammaGP(\n",
        "            model_dict[model], **train_few_shot_params, fast_inference=True\n",
        "        )\n",
        "        if num_draws is not None:\n",
        "            model.num_draws = num_draws\n",
        "        if num_steps is not None:\n",
        "            model.num_steps = num_steps\n",
        "        if sigma is not None:\n",
        "            model.kernel.sigma = sigma\n",
        "        return model\n",
        "    elif method == \"logistic_softmax_gp\":\n",
        "        model = LogisticSoftmaxGP(model_dict[model], **train_few_shot_params)\n",
        "        if num_draws is not None:\n",
        "            model.num_draws = num_draws\n",
        "        if num_steps is not None:\n",
        "            model.num_steps = num_steps\n",
        "        if sigma is not None:\n",
        "            model.kernel.sigma = sigma\n",
        "        return model\n",
        "    elif method == \"predictive_logistic_softmax_gp\":\n",
        "        model = PredictiveLogisticSoftmaxGP(model_dict[model], **train_few_shot_params)\n",
        "        if num_draws is not None:\n",
        "            model.num_draws = num_draws\n",
        "        if num_steps is not None:\n",
        "            model.num_steps = num_steps\n",
        "        if sigma is not None:\n",
        "            model.kernel.sigma = sigma\n",
        "        return model\n",
        "    elif method == \"bayesian_maml\":\n",
        "        model = BayesianMAML(\n",
        "            model_dict[model],\n",
        "            **train_few_shot_params,\n",
        "            num_draws=num_draws,\n",
        "            num_steps=num_steps\n",
        "        )\n",
        "        return model\n",
        "    elif method == \"chaser_bayesian_maml\":\n",
        "        return ChaserBayesianMAML(\n",
        "            model_dict[model],\n",
        "            **train_few_shot_params,\n",
        "            num_draws=num_draws,\n",
        "            num_steps=num_steps\n",
        "        )\n",
        "    elif method == \"gpnet\":\n",
        "        model = GPNet(model_dict[model], **train_few_shot_params)\n",
        "        model.init_summary()\n",
        "        return model\n",
        "    elif method == \"protonet\":\n",
        "        return ProtoNet(model_dict[model], **train_few_shot_params)\n",
        "    elif method == \"matchingnet\":\n",
        "        return MatchingNet(model_dict[model], **train_few_shot_params)\n",
        "    elif method in [\"relationnet\", \"relationnet_softmax\"]:\n",
        "        if model == \"Conv4\":\n",
        "            feature_model = backbone.Conv4NP\n",
        "        elif model == \"Conv6\":\n",
        "            feature_model = backbone.Conv6NP\n",
        "        elif model == \"Conv4S\":\n",
        "            feature_model = backbone.Conv4SNP\n",
        "        else:\n",
        "            feature_model = lambda: model_dict[model](flatten=False)\n",
        "        loss_type = \"mse\" if method == \"relationnet\" else \"softmax\"\n",
        "        return RelationNet(feature_model, loss_type=loss_type, **train_few_shot_params)\n",
        "    elif method in [\"maml\", \"maml_approx\"]:\n",
        "        backbone.ConvBlock.maml = True\n",
        "        backbone.SimpleBlock.maml = True\n",
        "        backbone.BottleneckBlock.maml = True\n",
        "        backbone.ResNet.maml = True\n",
        "        model = MAML(\n",
        "            model_dict[model], approx=(method == \"maml_approx\"), **train_few_shot_params\n",
        "        )\n",
        "        if dataset in [\n",
        "            \"omniglot\",\n",
        "            \"cross_char\",\n",
        "        ]:  # maml use different parameter in omniglot\n",
        "            model.n_task = 32\n",
        "            model.task_update_num = 1\n",
        "            model.train_lr = 0.1\n",
        "        return model\n",
        "    else:\n",
        "        raise ValueError(\"unknown method {}\".format(method))\n",
        "\n",
        "\n",
        "def _set_seed(seed, verbose=True):\n",
        "    if seed != 0:\n",
        "        random.seed(seed)\n",
        "        np.random.seed(seed)\n",
        "        torch.manual_seed(seed)\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "        if verbose:\n",
        "            print(\"[INFO] Setting SEED: \" + str(seed))\n",
        "    else:\n",
        "        if verbose:\n",
        "            print(\"[INFO] Setting SEED: None\")\n",
        "\n",
        "\n",
        "def train(\n",
        "    base_loader,\n",
        "    val_loader,\n",
        "    model,\n",
        "    optimizer,\n",
        "    start_epoch,\n",
        "    stop_epoch,\n",
        "    checkpoint_dir,\n",
        "    writer,\n",
        "    save_freq,\n",
        "    max_acc,\n",
        "    _run,\n",
        "):\n",
        "    print(\"Total epochs: {:d}\".format(stop_epoch))\n",
        "\n",
        "    for epoch in range(start_epoch, stop_epoch):\n",
        "        model.train()\n",
        "        train_loss = model.train_loop(epoch, base_loader, optimizer)\n",
        "        _run.log_scalar(\"train.loss\", train_loss)\n",
        "        writer.add_scalar(\"train.loss\", train_loss, epoch)\n",
        "\n",
        "        model.eval()\n",
        "        val_acc = model.test_loop(val_loader)\n",
        "        _run.log_scalar(\"val.acc\", val_acc)\n",
        "        writer.add_scalar(\"val.acc\", val_acc, epoch)\n",
        "\n",
        "        # for baseline and baseline++, we don't use validation here so we let acc = -1\n",
        "        if val_acc > max_acc:\n",
        "            print(\"--> Best model! save...\")\n",
        "            max_acc = val_acc\n",
        "            outfile = os.path.join(checkpoint_dir, \"best_model.pth\")\n",
        "            torch.save(\n",
        "                {\n",
        "                    \"epoch\": epoch,\n",
        "                    \"state\": model.state_dict(),\n",
        "                    \"optimizer_state\": optimizer.state_dict(),\n",
        "                    \"max_acc\": max_acc,\n",
        "                },\n",
        "                outfile,\n",
        "            )\n",
        "\n",
        "        if (epoch % save_freq == 0) or (epoch == stop_epoch - 1):\n",
        "            outfile = os.path.join(checkpoint_dir, \"last_model.pth\")\n",
        "            torch.save(\n",
        "                {\n",
        "                    \"epoch\": epoch,\n",
        "                    \"state\": model.state_dict(),\n",
        "                    \"optimizer_state\": optimizer.state_dict(),\n",
        "                    \"max_acc\": max_acc,\n",
        "                },\n",
        "                outfile,\n",
        "            )\n",
        "\n",
        "        writer.flush()\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "@ex.main\n",
        "def main(method, start_epoch, optimization, save_freq, tag, seed, _run):\n",
        "    print(\"using config: \", _run.config)\n",
        "    print(\"save_dir: \", get_save_dir())\n",
        "\n",
        "    validate_config()\n",
        "\n",
        "    _set_seed(seed)\n",
        "\n",
        "    max_acc = 0\n",
        "\n",
        "    base_loader = get_base_loader()\n",
        "    val_loader = get_val_loader()\n",
        "\n",
        "    model = get_model()\n",
        "    model = model.cuda()\n",
        "\n",
        "    if optimization == \"Adam\":\n",
        "        optimizer = torch.optim.Adam(model.parameters())\n",
        "    else:\n",
        "        raise ValueError(\"Unknown optimization, please define by yourself\")\n",
        "\n",
        "    stop_epoch = get_stop_epoch()\n",
        "\n",
        "    if method == \"maml\" or method == \"maml_approx\":\n",
        "        stop_epoch *= model.n_task  # maml use multiple tasks in one update\n",
        "\n",
        "    writer = SummaryWriter(os.path.join(RUN_DIR, EXPERIMENT_NAME, tag, _run._id))\n",
        "\n",
        "    model = train(\n",
        "        base_loader,\n",
        "        val_loader,\n",
        "        model,\n",
        "        optimizer,\n",
        "        start_epoch,\n",
        "        stop_epoch,\n",
        "        os.path.join(get_save_dir(), str(_run._id)),\n",
        "        writer,\n",
        "        save_freq,\n",
        "        max_acc,\n",
        "        _run,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mm = train(method=ove_polya_gamma_gp,dataset=CUB,train_aug=True,kernel.name=L2LinearKernel,num_draws=20,num_steps=1,n_shot=5)"
      ],
      "metadata": {
        "id": "uTOM_bt3l303"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import tqdm\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "import torch.optim\n",
        "import torch.utils.data.sampler\n",
        "import os\n",
        "import time\n",
        "\n",
        "import configs\n",
        "import backbone\n",
        "import data.feature_loader as feat_loader\n",
        "from data.datamgr import SetDataManager\n",
        "from methods.baselinefinetune import BaselineFinetune\n",
        "from methods.protonet import ProtoNet\n",
        "from methods.ove_polya_gamma_gp import OVEPolyaGammaGP, PredictiveOVEPolyaGammaGP\n",
        "from methods.logistic_softmax_gp import LogisticSoftmaxGP, PredictiveLogisticSoftmaxGP\n",
        "from methods.bayesian_maml import BayesianMAML, ChaserBayesianMAML\n",
        "from methods.gpnet import GPNet\n",
        "from methods.matchingnet import MatchingNet\n",
        "from methods.relationnet import RelationNet\n",
        "from methods.maml import MAML\n",
        "from io_utils import model_dict, parse_args, get_best_file, get_assigned_file\n",
        "\n",
        "from methods.ove_polya_gamma_gp import kernel_ingredient\n",
        "\n",
        "from calibrate import ECELoss\n",
        "\n",
        "from sacred import Experiment\n",
        "from sacred.observers import FileStorageObserver\n",
        "\n",
        "EXPERIMENT_NAME = \"test\"\n",
        "\n",
        "\n",
        "def get_save_dir():\n",
        "    return os.path.join(\"runs\", EXPERIMENT_NAME)\n",
        "\n",
        "\n",
        "ex = Experiment(EXPERIMENT_NAME, ingredients=[kernel_ingredient],interactive=True)\n",
        "ex.observers.append(FileStorageObserver(get_save_dir()))\n",
        "\n",
        "\n",
        "@ex.capture\n",
        "def get_checkpoint_dir(_run):\n",
        "    return os.path.join(get_save_dir(), str(_run._id))\n",
        "\n",
        "\n",
        "@ex.config\n",
        "def get_config():\n",
        "    # where runs are located\n",
        "    run_dir = \"runs/train\"\n",
        "\n",
        "    # job id to evaluate\n",
        "    job_id = -1\n",
        "\n",
        "    # saved feature from the model trained in x epoch, use the best model if x is -1\n",
        "    save_iter = -1\n",
        "\n",
        "    # number of episodes to test\n",
        "    num_episodes = 600\n",
        "\n",
        "    # relationnet_softmax replace L2 norm with softmax to expedite training,\n",
        "    # maml_approx use first-order approximation in the gradient for efficiency\n",
        "    # if default, match whatever setting was found in the job config\n",
        "    # baseline/baseline++/protonet/matchingnet/relationnet{_softmax}/maml{_approx}\n",
        "    method = \"default\"\n",
        "\n",
        "    # baseline and baseline++ only use this parameter in finetuning\n",
        "    # number of labeled data in each class, same as n_support\n",
        "    n_shot = 5\n",
        "\n",
        "    # baseline and baseline++ only use this parameter in finetuning\n",
        "    # class num to classify for testing (validation)\n",
        "    test_n_way = 5\n",
        "\n",
        "    # default novel, but you can also test base/val class accuracy if you want\n",
        "    # base/val/novel\n",
        "    split = \"novel\"\n",
        "\n",
        "    # further adaptation in test time or not\n",
        "    adaptation = False\n",
        "\n",
        "    # Repeat the test N times with different seeds and take the mean. The seeds range is [seed, seed+repeat]\n",
        "    repeat = 5\n",
        "\n",
        "    # number of draws for polya-gamma gps\n",
        "    num_draws = None\n",
        "\n",
        "    # number of steps for polya-gamma gps\n",
        "    num_steps = None\n",
        "\n",
        "    # Seed for Numpy and pyTorch. Default: 0 (None)\n",
        "    seed = 0\n",
        "\n",
        "    # tag (for logging purposes)\n",
        "    tag = \"default\"\n",
        "\n",
        "    # command allows specification of which evaluation to run\n",
        "    command = \"evaluate\"\n",
        "\n",
        "    # command = shot_sweep\n",
        "    shot_sweep_min_shot = 1\n",
        "    shot_sweep_max_shot = 20\n",
        "\n",
        "    # None for no noise for default, otherwise 0-14\n",
        "    noise_type = None\n",
        "\n",
        "    # None for no noise, otherwise 1-5\n",
        "    noise_strength = None\n",
        "\n",
        "    run_prefix = \"\"\n",
        "\n",
        "\n",
        "def _set_seed(seed, verbose=True):\n",
        "    if seed != 0:\n",
        "        random.seed(seed)\n",
        "        np.random.seed(seed)\n",
        "        torch.manual_seed(seed)\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "        if verbose:\n",
        "            print(\"[INFO] Setting SEED: \" + str(seed))\n",
        "    else:\n",
        "        if verbose:\n",
        "            print(\"[INFO] Setting SEED: None\")\n",
        "\n",
        "\n",
        "@ex.capture\n",
        "def feature_evaluation(\n",
        "    cl_data_file, model, test_n_way, n_shot, n_query=15, adaptation=False\n",
        "):\n",
        "    class_list = cl_data_file.keys()\n",
        "\n",
        "    select_class = random.sample(class_list, test_n_way)\n",
        "    z_all = []\n",
        "    for cl in select_class:\n",
        "        img_feat = cl_data_file[cl]\n",
        "        perm_ids = np.random.permutation(len(img_feat)).tolist()\n",
        "        z_all.append(\n",
        "            [np.squeeze(img_feat[perm_ids[i]]) for i in range(n_shot + n_query)]\n",
        "        )  # stack each batch\n",
        "\n",
        "    z_all = torch.from_numpy(np.array(z_all))\n",
        "\n",
        "    model.n_query = n_query\n",
        "    if adaptation:\n",
        "        scores = model.set_forward_adaptation(z_all, is_feature=True)\n",
        "    else:\n",
        "        scores = model.set_forward(z_all, is_feature=True)\n",
        "    pred = scores.data.cpu().numpy().argmax(axis=1)\n",
        "    y = np.repeat(range(test_n_way), n_query)\n",
        "    acc = np.mean(pred == y) * 100\n",
        "    return acc, {\"logits\": scores, \"targets\": y}\n",
        "\n",
        "\n",
        "@ex.capture\n",
        "def validate_config(job_id):\n",
        "    # job id checks\n",
        "    assert job_id != -1, \"must specify which job id to evaluate\"\n",
        "\n",
        "\n",
        "@ex.capture\n",
        "def get_model(test_n_way, n_shot, num_draws, num_steps):\n",
        "    model = get_job_config()[\"model\"]\n",
        "    dataset = get_job_config()[\"dataset\"]\n",
        "    method = get_method()\n",
        "    few_shot_params = dict(n_way=test_n_way, n_support=n_shot)\n",
        "\n",
        "    if method == \"baseline\":\n",
        "        return BaselineFinetune(model_dict[model], **few_shot_params)\n",
        "    elif method == \"baseline++\":\n",
        "        return BaselineFinetune(model_dict[model], loss_type=\"dist\", **few_shot_params)\n",
        "    elif method == \"ove_polya_gamma_gp\":\n",
        "        return OVEPolyaGammaGP(model_dict[model], **few_shot_params)\n",
        "    elif method == \"predictive_ove_polya_gamma_gp\":\n",
        "        model = PredictiveOVEPolyaGammaGP(model_dict[model], **few_shot_params)\n",
        "        return model\n",
        "    elif method == \"logistic_softmax_gp\":\n",
        "        return LogisticSoftmaxGP(model_dict[model], **few_shot_params)\n",
        "    elif method == \"predictive_logistic_softmax_gp\":\n",
        "        return PredictiveLogisticSoftmaxGP(model_dict[model], **few_shot_params)\n",
        "    elif method == \"bayesian_maml\":\n",
        "        return BayesianMAML(\n",
        "            model_dict[model],\n",
        "            num_draws=num_draws,\n",
        "            num_steps=num_steps,\n",
        "            **few_shot_params\n",
        "        )\n",
        "    elif method == \"chaser_bayesian_maml\":\n",
        "        return ChaserBayesianMAML(\n",
        "            model_dict[model],\n",
        "            num_draws=num_draws,\n",
        "            num_steps=num_steps,\n",
        "            **few_shot_params\n",
        "        )\n",
        "    elif method == \"gpnet\":\n",
        "        return GPNet(model_dict[model], **few_shot_params)\n",
        "    elif method == \"protonet\":\n",
        "        return ProtoNet(model_dict[model], **few_shot_params)\n",
        "    elif method == \"matchingnet\":\n",
        "        return MatchingNet(model_dict[model], **few_shot_params)\n",
        "    elif method in [\"relationnet\", \"relationnet_softmax\"]:\n",
        "        if model == \"Conv4\":\n",
        "            feature_model = backbone.Conv4NP\n",
        "        elif model == \"Conv6\":\n",
        "            feature_model = backbone.Conv6NP\n",
        "        elif model == \"Conv4S\":\n",
        "            feature_model = backbone.Conv4SNP\n",
        "        else:\n",
        "            feature_model = lambda: model_dict[model](flatten=False)\n",
        "        loss_type = \"mse\" if method == \"relationnet\" else \"softmax\"\n",
        "        return RelationNet(feature_model, loss_type=loss_type, **few_shot_params)\n",
        "    elif method in [\"maml\", \"maml_approx\"]:\n",
        "        backbone.ConvBlock.maml = True\n",
        "        backbone.SimpleBlock.maml = True\n",
        "        backbone.BottleneckBlock.maml = True\n",
        "        backbone.ResNet.maml = True\n",
        "        model = MAML(\n",
        "            model_dict[model], approx=(method == \"maml_approx\"), **few_shot_params\n",
        "        )\n",
        "        if dataset in [\n",
        "            \"omniglot\",\n",
        "            \"cross_char\",\n",
        "        ]:  # maml use different parameter in omniglot\n",
        "            model.n_task = 32\n",
        "            model.task_update_num = 1\n",
        "            model.train_lr = 0.1\n",
        "        return model\n",
        "    else:\n",
        "        raise ValueError(\"unknown method {}\".format(method))\n",
        "\n",
        "\n",
        "@ex.capture\n",
        "def get_job_dir(run_dir, job_id):\n",
        "    return os.path.join(run_dir, str(job_id))\n",
        "\n",
        "\n",
        "@ex.capture\n",
        "def get_job_config(run_dir, job_id, run_prefix):\n",
        "    with open(os.path.join(get_job_dir(), str(run_prefix), \"config.json\")) as f:\n",
        "        return json.load(f)\n",
        "\n",
        "\n",
        "@ex.capture\n",
        "def get_checkpoint_file(save_iter):\n",
        "    job_dir = get_job_dir()\n",
        "\n",
        "    if save_iter != -1:\n",
        "        return get_assigned_file(job_dir, save_iter)\n",
        "    else:\n",
        "        return get_best_file(job_dir)\n",
        "\n",
        "\n",
        "@ex.capture\n",
        "def load_model(n_shot, test_n_way, num_draws, num_steps, method):\n",
        "    model = get_model(\n",
        "        n_shot=n_shot, test_n_way=test_n_way, num_draws=num_draws, num_steps=num_steps\n",
        "    )\n",
        "    model = model.cuda()\n",
        "\n",
        "    # for baseline/baseline++ just use feature evaluation\n",
        "    if get_method() not in [\"baseline\", \"baseline++\"]:\n",
        "        state_dict = torch.load(get_checkpoint_file())[\"state\"]\n",
        "\n",
        "        # model.num_steps = 1\n",
        "\n",
        "        # # TODO: configure this better\n",
        "        if method != \"default\":\n",
        "            print(\"method is not default. Assuming transfer from baseline to gp...\")\n",
        "            state_dict[\"kernel.output_scale_raw\"] = torch.Tensor([1.0]).log()\n",
        "\n",
        "            for k in [\n",
        "                \"classifier.weight\",\n",
        "                \"classifier.bias\",\n",
        "                \"classifier.L.weight_g\",\n",
        "                \"classifier.L.weight_v\",\n",
        "            ]:\n",
        "                if k in state_dict:\n",
        "                    del state_dict[k]\n",
        "\n",
        "        model.load_state_dict(state_dict)\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    if num_draws is not None:\n",
        "        model.num_draws = num_draws\n",
        "\n",
        "    if num_steps is not None:\n",
        "        model.num_steps = num_steps\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "@ex.capture\n",
        "def get_method(method):\n",
        "    if method == \"default\":\n",
        "        return get_job_config()[\"method\"]\n",
        "    else:\n",
        "        return method\n",
        "\n",
        "\n",
        "def get_image_size():\n",
        "    model = get_job_config()[\"model\"]\n",
        "    dataset = get_job_config()[\"dataset\"]\n",
        "    if \"Conv\" in model:\n",
        "        if dataset in [\"omniglot\", \"cross_char\"]:\n",
        "            return 28\n",
        "        else:\n",
        "            return 84\n",
        "    else:\n",
        "\n",
        "        return 224\n",
        "\n",
        "\n",
        "@ex.capture\n",
        "def get_split_file(split):\n",
        "    dataset = get_job_config()[\"dataset\"]\n",
        "    if dataset == \"cross\":\n",
        "        if split == \"base\":\n",
        "            return configs.data_dir[\"miniImagenet\"] + \"all.json\"\n",
        "        else:\n",
        "            return configs.data_dir[\"CUB\"] + split + \".json\"\n",
        "    elif dataset == \"cross_char\":\n",
        "        if split == \"base\":\n",
        "            return configs.data_dir[\"omniglot\"] + \"noLatin.json\"\n",
        "        else:\n",
        "            return configs.data_dir[\"emnist\"] + split + \".json\"\n",
        "    else:\n",
        "        return configs.data_dir[dataset] + split + \".json\"\n",
        "\n",
        "\n",
        "@ex.capture\n",
        "def get_feature_file(split):\n",
        "    ret = os.path.join(get_job_dir(), \"{}_features.hdf5\".format(split))\n",
        "    if os.path.isfile(ret):\n",
        "        return ret\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "\n",
        "@ex.capture\n",
        "def get_loader(\n",
        "    iter_num, test_n_way, n_shot, method, noise_type, noise_strength, command\n",
        "):\n",
        "    print(\"loading with {:d} way and {:d} shot\".format(test_n_way, n_shot))\n",
        "    feature_file = get_feature_file()\n",
        "\n",
        "    if feature_file is not None and noise_type is None and command != \"ooe\":\n",
        "        return feat_loader.init_loader(feature_file)\n",
        "    else:\n",
        "        datamgr = SetDataManager(\n",
        "            get_image_size(),\n",
        "            n_eposide=iter_num,\n",
        "            n_query=15,\n",
        "            n_way=test_n_way,\n",
        "            n_support=n_shot,\n",
        "        )\n",
        "        if noise_type is None:\n",
        "            return datamgr.get_data_loader(get_split_file(), aug=False)\n",
        "        else:\n",
        "            return datamgr.get_noisy_data_loader(\n",
        "                get_split_file(), noise_type, noise_strength\n",
        "            )\n",
        "\n",
        "\n",
        "def repeat_iterator(iterable):\n",
        "    while True:\n",
        "        for item in iterable:\n",
        "            yield item\n",
        "\n",
        "\n",
        "class EpochLoader:\n",
        "    def __init__(self, iterable, num_episodes):\n",
        "        self.iterable = repeat_iterator(iterable)\n",
        "        self.num_episodes = num_episodes\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_episodes\n",
        "\n",
        "    def __iter__(self):\n",
        "        for _ in range(self.num_episodes):\n",
        "            yield self.convert_to_episode(next(self.iterable))\n",
        "\n",
        "    def canonicalize(self, inputs, targets):\n",
        "        assert inputs.size(0) == 1\n",
        "        assert targets.size(0) == 1\n",
        "        inputs = inputs[0]\n",
        "        targets = targets[0]\n",
        "\n",
        "        class_counts = torch.bincount(targets)\n",
        "        assert torch.all(\n",
        "            class_counts.eq(class_counts[0])\n",
        "        ), \"classes not balanced, cannot convert\"\n",
        "\n",
        "        shot = class_counts[0].item()\n",
        "        way = class_counts.size(0)\n",
        "\n",
        "        assert (\n",
        "            targets.size(0) == shot * way\n",
        "        ), \"number of examples does not match shot * way\"\n",
        "\n",
        "        # reshape to class batched format\n",
        "        inputs = inputs.reshape(way, shot, *inputs.size()[1:])\n",
        "        targets = targets.reshape(way, shot)\n",
        "\n",
        "        way_permutation = targets[:, 0].argsort()\n",
        "\n",
        "        inputs = inputs[way_permutation]\n",
        "        targets = targets[way_permutation]\n",
        "\n",
        "        assert torch.all(\n",
        "            targets.eq(torch.arange(way).unsqueeze(-1))\n",
        "        ), \"problem with class permutation\"\n",
        "\n",
        "        return inputs, targets\n",
        "\n",
        "    def convert_to_episode(self, sample):\n",
        "        train_inputs, train_targets = self.canonicalize(*sample[\"train\"])\n",
        "        test_inputs, test_targets = self.canonicalize(*sample[\"test\"])\n",
        "\n",
        "        return (\n",
        "            torch.cat([train_inputs, test_inputs], 1),\n",
        "            torch.cat([train_targets, test_targets], 1),\n",
        "        )\n",
        "\n",
        "\n",
        "def load_feature_extractor():\n",
        "    method = get_job_config()[\"method\"]\n",
        "    model = get_job_config()[\"model\"]\n",
        "\n",
        "    if method in [\"relationnet\", \"relationnet_softmax\"]:\n",
        "        if model == \"Conv4\":\n",
        "            extractor = backbone.Conv4NP()\n",
        "        elif model == \"Conv6\":\n",
        "            extractor = backbone.Conv6NP()\n",
        "        elif model == \"Conv4S\":\n",
        "            extractor = backbone.Conv4SNP()\n",
        "        else:\n",
        "            extractor = model_dict[model](flatten=False)\n",
        "    elif method in [\"maml\", \"maml_approx\"]:\n",
        "        raise ValueError(\"MAML do not support save feature\")\n",
        "    else:\n",
        "        extractor = model_dict[model]()\n",
        "\n",
        "    extractor = extractor.cuda()\n",
        "\n",
        "    state = torch.load(get_checkpoint_file())[\"state\"]\n",
        "    state_keys = list(state.keys())\n",
        "    for i, key in enumerate(state_keys):\n",
        "        if \"feature.\" in key:\n",
        "            newkey = key.replace(\n",
        "                \"feature.\", \"\"\n",
        "            )  # an architecture model has attribute 'feature', load architecture feature to backbone by casting name from 'feature.trunk.xx' to 'trunk.xx'\n",
        "            state[newkey] = state.pop(key)\n",
        "        else:\n",
        "            state.pop(key)\n",
        "\n",
        "    extractor.load_state_dict(state)\n",
        "    extractor.eval()\n",
        "\n",
        "    return extractor\n",
        "\n",
        "\n",
        "@ex.capture\n",
        "def single_test(model, n_shot, test_n_way, split, adaptation, num_episodes):\n",
        "    loader = get_loader(num_episodes, n_shot=n_shot, test_n_way=test_n_way)\n",
        "\n",
        "    if adaptation:\n",
        "        # We perform adaptation on MAML simply by updating more times.\n",
        "        model.task_update_num = 100\n",
        "\n",
        "    if isinstance(loader, dict):\n",
        "        acc_all = []\n",
        "        stats_all = []\n",
        "        pbar = tqdm.tqdm(range(num_episodes))\n",
        "        for _ in pbar:\n",
        "            acc, stats = feature_evaluation(\n",
        "                loader,\n",
        "                model,\n",
        "                n_shot=n_shot,\n",
        "                test_n_way=test_n_way,\n",
        "                adaptation=adaptation,\n",
        "            )\n",
        "            acc_all.append(acc)\n",
        "            stats_all.append(stats)\n",
        "            pbar.set_description(\"Acc {:f}\".format(np.mean(acc_all)))\n",
        "        acc_mean = np.mean(acc_all)\n",
        "        acc_std = np.std(acc_all)\n",
        "\n",
        "        stats_final = {}\n",
        "        for k in stats_all[0].keys():\n",
        "            stats_final[k] = (\n",
        "                torch.cat([torch.as_tensor(stats[k]) for stats in stats_all], 0)\n",
        "                .detach()\n",
        "                .cpu()\n",
        "            )\n",
        "\n",
        "        return {\"acc_mean\": acc_mean, \"acc_std\": acc_std, \"stats\": stats_final}\n",
        "    else:\n",
        "        if get_method() in [\"baseline\", \"baseline++\"]:\n",
        "            feature_extractor = load_feature_extractor()\n",
        "            return model.test_loop(\n",
        "                loader,\n",
        "                use_progress=True,\n",
        "                return_stats=True,\n",
        "                feature_extractor=feature_extractor,\n",
        "            )\n",
        "        else:\n",
        "            return model.test_loop(loader, use_progress=True, return_stats=True)\n",
        "\n",
        "\n",
        "@ex.capture\n",
        "def ooe_evaluation(model, n_shot, test_n_way, split, adaptation, num_episodes):\n",
        "    loader = get_loader(num_episodes, n_shot=n_shot, test_n_way=2 * test_n_way)\n",
        "\n",
        "    if adaptation:\n",
        "        # We perform adaptation on MAML simply by updating more times.\n",
        "        model.task_update_num = 100\n",
        "\n",
        "    if get_method() in [\"baseline\", \"baseline++\"]:\n",
        "        feature_extractor = load_feature_extractor()\n",
        "    else:\n",
        "        feature_extractor = None\n",
        "\n",
        "    targets_all = []\n",
        "    logits_all = []\n",
        "\n",
        "    pbar = tqdm.tqdm(loader)\n",
        "    for x, _ in pbar:\n",
        "        # 2C x N x ...\n",
        "        x_support = x[:test_n_way, :n_shot]\n",
        "        x_query = x[:test_n_way, n_shot:]\n",
        "        x_distractor = x[test_n_way:, n_shot:]\n",
        "\n",
        "        x = torch.cat([x_support, x_query, x_distractor], 1)\n",
        "        model.n_query = x.size(1) - n_shot\n",
        "\n",
        "        if feature_extractor is not None:\n",
        "            x_flat = x.view(-1, *x.size()[2:])\n",
        "            x_flat = feature_extractor(x_flat.cuda())\n",
        "            x = x_flat.view(*x.size()[:2], -1)\n",
        "\n",
        "        if isinstance(model, GPNet):\n",
        "            _, _, _, scores = model.correct(x)\n",
        "            logits_all.append(scores)\n",
        "        else:\n",
        "            scores = model.set_forward(x)\n",
        "            logits_all.append(scores.cpu().detach().numpy())\n",
        "\n",
        "        y_query = np.repeat(range(model.n_way), model.n_query)\n",
        "        y_query = y_query.reshape(model.n_way, -1)\n",
        "        y_query[:, y_query.shape[1] // 2 :] = -1\n",
        "        y_query = y_query.reshape(-1)\n",
        "\n",
        "        targets_all.append(y_query)\n",
        "\n",
        "    return {\n",
        "        \"stats\": {\n",
        "            \"logits\": torch.as_tensor(np.concatenate(logits_all, 0)),\n",
        "            \"targets\": torch.as_tensor(np.concatenate(targets_all, 0)),\n",
        "        }\n",
        "    }\n",
        "\n",
        "\n",
        "@ex.capture\n",
        "def shot_sweep(num_episodes, shot_sweep_min_shot, shot_sweep_max_shot, num_draws, _run):\n",
        "    for shot in range(shot_sweep_min_shot, shot_sweep_max_shot + 1):\n",
        "        target_file = os.path.join(\n",
        "            get_checkpoint_dir(), \"results_shot-{:02d}.pth\".format(shot)\n",
        "        )\n",
        "        if os.path.isfile(target_file):\n",
        "            continue\n",
        "\n",
        "        model = load_model(n_shot=shot)\n",
        "        if num_draws is not None:\n",
        "            model.num_draws = num_draws\n",
        "\n",
        "        results = single_test(model, n_shot=shot, num_episodes=num_episodes)\n",
        "\n",
        "        _run.log_scalar(\"shot\", shot)\n",
        "        _run.log_scalar(\"acc_mean\", results[\"acc_mean\"])\n",
        "        _run.log_scalar(\"acc_std\", results[\"acc_std\"])\n",
        "        print(\n",
        "            \"{:d} shot: {:4.2f} +/- {:4.2f}\".format(\n",
        "                shot, results[\"acc_mean\"], results[\"acc_std\"]\n",
        "            )\n",
        "        )\n",
        "\n",
        "        torch.save(results, target_file)\n",
        "\n",
        "\n",
        "@ex.capture\n",
        "def way_sweep(num_episodes, shot_sweep_min_shot, shot_sweep_max_shot, num_draws, _run):\n",
        "    for way in range(max(2, shot_sweep_min_shot), shot_sweep_max_shot + 1):\n",
        "        target_file = os.path.join(\n",
        "            get_checkpoint_dir(), \"results_way-{:02d}.pth\".format(way)\n",
        "        )\n",
        "        if os.path.isfile(target_file):\n",
        "            continue\n",
        "\n",
        "        model = load_model(test_n_way=way)\n",
        "        if num_draws is not None:\n",
        "            model.num_draws = num_draws\n",
        "\n",
        "        results = single_test(model, test_n_way=way, num_episodes=num_episodes)\n",
        "\n",
        "        _run.log_scalar(\"way\", way)\n",
        "        _run.log_scalar(\"acc_mean\", results[\"acc_mean\"])\n",
        "        _run.log_scalar(\"acc_std\", results[\"acc_std\"])\n",
        "\n",
        "        print(\n",
        "            \"{:d} way: {:4.2f} +/- {:4.2f}\".format(\n",
        "                way, results[\"acc_mean\"], results[\"acc_std\"]\n",
        "            )\n",
        "        )\n",
        "\n",
        "        torch.save(results, target_file)\n",
        "\n",
        "\n",
        "@ex.capture\n",
        "def scale_sweep(num_episodes, num_draws):\n",
        "    print(\"running scale_sweep\")\n",
        "\n",
        "    results_all = []\n",
        "\n",
        "    max_bias = 1.5\n",
        "    num_points = 11\n",
        "\n",
        "    for exp in torch.linspace(-max_bias, max_bias, num_points + 1):\n",
        "        model = load_model()\n",
        "        if num_draws is not None:\n",
        "            model.num_draws = num_draws\n",
        "        model.kernel.output_scale_raw.data.fill_(\n",
        "            model.kernel.output_scale_raw.item() + exp\n",
        "        )\n",
        "        print(\"scale = \", model.kernel.output_scale_raw[:].exp())\n",
        "\n",
        "        results = single_test(model)\n",
        "        print(\"{:0.2f} scale: {:4.2f}\".format(exp, results[\"acc_mean\"]))\n",
        "\n",
        "        results_all.append((exp, results))\n",
        "\n",
        "    return results_all\n",
        "\n",
        "\n",
        "@ex.capture\n",
        "def noise_sweep(num_episodes, num_draws):\n",
        "    print(\"running noise_sweep\")\n",
        "\n",
        "    for noise in [0.0, 1e-2, 1e-1, 1e0, 1e1]:\n",
        "        model = load_model()\n",
        "        if num_draws is not None:\n",
        "            model.num_draws = num_draws\n",
        "        model.noise = noise\n",
        "        print(\"noise = \", model.noise)\n",
        "        loader = get_loader(iter_num=num_episodes)\n",
        "        acc_mean = model.test_loop(loader, use_progress=True)\n",
        "        print(\"{:f} noise: {:4.2f}\".format(noise, acc_mean))\n",
        "\n",
        "\n",
        "@ex.main\n",
        "def main(command, seed, repeat, _run):\n",
        "    print(\"using config: \", _run.config)\n",
        "    print(\"save_dir: \", get_save_dir())\n",
        "\n",
        "    validate_config()\n",
        "\n",
        "    if command == \"evaluate\":\n",
        "        accuracy_list = []\n",
        "        results_all = []\n",
        "\n",
        "        # repeat the test N times changing the seed in range [seed, seed+repeat]\n",
        "        for i in range(seed, seed + repeat):\n",
        "            if seed != 0:\n",
        "                _set_seed(i)\n",
        "            else:\n",
        "                _set_seed(0)\n",
        "\n",
        "            model = load_model()\n",
        "            results = single_test(model)\n",
        "            results_all.append(results)\n",
        "            accuracy_list.append(results[\"acc_mean\"])\n",
        "            _run.log_scalar(\"acc\", results[\"acc_mean\"])\n",
        "        print(\"-----------------------------\")\n",
        "        print(\n",
        "            \"Seeds = %d | Overall Test Acc = %4.2f%% +- %4.2f%%\"\n",
        "            % (repeat, np.mean(accuracy_list), np.std(accuracy_list))\n",
        "        )\n",
        "        print(\"-----------------------------\")\n",
        "        torch.save(results_all, os.path.join(get_checkpoint_dir(), \"results.pth\"))\n",
        "\n",
        "        logits = torch.cat(\n",
        "            [result[\"stats\"][\"logits\"] for result in results_all], 0\n",
        "        ).cuda()\n",
        "        targets = torch.cat(\n",
        "            [result[\"stats\"][\"targets\"] for result in results_all], 0\n",
        "        ).cuda()\n",
        "\n",
        "        ece_module = ECELoss().cuda()\n",
        "        ece_val = ece_module.forward(logits, targets)\n",
        "        print(\"ece: \", ece_val)\n",
        "        _run.log_scalar(\"ece\", ece_val.item())\n",
        "    elif command == \"shot_sweep\":\n",
        "        _set_seed(seed)\n",
        "        shot_sweep()\n",
        "    elif command == \"way_sweep\":\n",
        "        _set_seed(seed)\n",
        "        way_sweep()\n",
        "    elif command == \"scale_sweep\":\n",
        "        _set_seed(seed)\n",
        "        results_all = scale_sweep()\n",
        "        torch.save(results_all, os.path.join(get_checkpoint_dir(), \"results.pth\"))\n",
        "    elif command == \"noise_sweep\":\n",
        "        _set_seed(seed)\n",
        "        noise_sweep()\n",
        "    elif command == \"ooe\":\n",
        "        results_all = []\n",
        "        # repeat the test N times changing the seed in range [seed, seed+repeat]\n",
        "        for i in range(seed, seed + repeat):\n",
        "            if seed != 0:\n",
        "                _set_seed(i)\n",
        "            else:\n",
        "                _set_seed(0)\n",
        "\n",
        "            model = load_model()\n",
        "            results = ooe_evaluation(model)\n",
        "            results_all.append(results)\n",
        "        torch.save(results_all, os.path.join(get_checkpoint_dir(), \"results.pth\"))\n",
        "    else:\n",
        "        raise ValueError(\"unknown command {}\".format(command))"
      ],
      "metadata": {
        "id": "qKPjYxawYi7S"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}